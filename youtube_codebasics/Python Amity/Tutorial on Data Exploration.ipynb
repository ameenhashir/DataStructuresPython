{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Tutorial 2:   Data Exploration in Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration is one of the key step in data analysis. It involves basic task of getting primilarlary understanding on data such as, data structure, statistical distribution of features, interrelationships within features and more. There are following two motivations of using data exploration.\n",
    "\n",
    "1. It helps in selecting appropriate data-preprocessing technique for the data set\n",
    "2. Data exploration analysis helps in selecting suitable machine learning technique\n",
    "\n",
    "Python library Pandas is a powerful way of gaining understanding on data.  Pandas is packed with several smart data manipulation and exploration methods that can be used for basic data analysis. Pandas when integrated with visualization tools can give deep understanding of data. The task of data exploration will use following two main libraries in Python\n",
    "\n",
    "$\\textbf{1. Pandas}$  \n",
    "\n",
    "$\\textbf{2. Matplotlib/Seaborn}$ \n",
    "\n",
    "Data exploration is divided into 3 main steps as described following:\n",
    "\n",
    "$\\textbf{1. Basic data details }$ \n",
    "\n",
    "$\\textbf{2. Summary Statistics}$\n",
    "\n",
    "$\\textbf{3. Data Visualization}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Basic Data Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pandas, data sets of different formats can be loaded into python enviornment for analysis. Pandas reads the tabular data set as DataFrame object. The three common methods\n",
    "used to read data set are as follows:\n",
    "\n",
    "1. read_csv() : it uses commas as seperating delimeter\n",
    "\n",
    "2. read_table() : it considers '\\t' as default delimeter\n",
    "\n",
    "3. read_excel() : it reads excel file\n",
    "\n",
    "$\\color{red}{Code:}$ The following code uses Pandas to read the CSV file stored on a specific location of the computer and saves it to in a DataFrame object named data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Grocery_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{Code}$: The size of the data set loaded in dataframe of pandas can be printed using following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The number of rows in data set:\", len(data))\n",
    "print(\"The number of columns in data set:\", len(data.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{Code}$: The data types of features can be printed using following code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item_Identifier               object\n",
      "Item_Weight                  float64\n",
      "Item_Fat_Content              object\n",
      "Item_Visibility              float64\n",
      "Item_Type                     object\n",
      "Item_MRP                     float64\n",
      "Outlet_Identifier             object\n",
      "Outlet_Establishment_Year      int64\n",
      "Outlet_Size                   object\n",
      "Outlet_Location_Type          object\n",
      "Outlet_Type                   object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{Code}$: The following code helps in changing data type of given feature to some different dtype. For example, converting int data type to float and vice versa, float to object and likewise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.Outlet_Establishment_Year = (data.Outlet_Establishment_Year).astype(float) \n",
    "data.Item_Visibility = (data.Item_Visibility).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{Code}$: The following code gets basic statistics of numerical features of the data set such as mean, standard deviation, minimum and maximum value.  For the qualitative attributes in data set, it counts the frequency for each of its distinct values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import is_numeric_dtype\n",
    "from pandas.api.types import is_object_dtype\n",
    "for col in data.columns:\n",
    "    if is_numeric_dtype(data[col]):\n",
    "        print('%s:' % (col))\n",
    "        print('\\t Mean = %.2f' % data[col].mean())\n",
    "        print('\\t Standard deviation = %.2f' % data[col].std())\n",
    "        print('\\t Minimum = %.2f' % data[col].min())\n",
    "        print('\\t Maximum = %.2f' % data[col].max())\n",
    "    if is_object_dtype(data[col]):\n",
    "        print(data[col].value_counts())\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{Code}$: We can also  display the summary for all the attributes simultaneously in a table using the describe() function. If an attribute is quantitative, it will display its mean, standard deviation and various quantiles (including minimum, median, and maximum) values. If an attribute is qualitative, it will display its number of unique values and the top (most frequent) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{Code}$: The Covariance and Correlation among numerical features can be printed using following code\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Correlation:')\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Covariance:')\n",
    "data.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{Code} :$ The distribution of the feature can be visualized by creating histograms. The histograms are binned for numerical features used hist() function of Pandas data frame whereas, for categorical columns we plot bar plot() using the value_count() and plot.bar(). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{Code} :$ The following code demonstrate the plotting of histogram of a given feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "data['Item_Weight'].hist(bins=8)\n",
    "plt.title('Distribution of Feature')\n",
    "plt.xlabel('Range of bins')\n",
    "plt.ylabel('# of data points falling in bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{Code} :$ The following code demonstrate the plotting of bar plot of a given feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Item_Fat_Content'].value_counts().plot.bar(title='Freq dist of Item_Identifier')\n",
    "plt.title('Distribution of Feature')\n",
    "plt.xlabel('Range of bins')\n",
    "plt.ylabel('# of data points falling in bins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{Code}$:  A boxplot can also be used to show the distribution of values for each attribute. The code below shows the boxplot of two selected features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.boxplot(column=['Item_Weight','Item_MRP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{Code}$: For each pair of attributes, we can use a scatter plot to visualize their joint distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.scatter_matrix(data, alpha=0.2, figsize=(10, 10))\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\color{red}{Code :}$ The following code plots a correlation matrix plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(data.corr())\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download the iris data set from https://archive.ics.uci.edu/ml/datasets/Iris . Read the data set in Python. Analyse all fetaures statiscally and interpret correlation results.\n",
    "\n",
    "2. Download the Housing data set from https://archive.ics.uci.edu/ml/machine-learning-databases/housing/ . Read the data set in Python. Analyse all fetaures statiscally and interpret correlation results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
